= Installation Guide
:toc:

This guide will show how to install ODS Pipeline in an existing ODS project. It is possible to use ODS Pipeline and the classic Jenkins CI/CD setup side by side.

An ODS Pipeline installation consists of the following resources:

* A pipeline manager, which is creating pipeline runs in response to Bitbucket webhook requests
* A start and finish task which will get injected into every pipeline run
* `ConfigMap` and `Secret` resources, e.g. holding credentials of centrally installed tools such as Nexus and Bitbucket


== Prerequisites

You'll need:

* A namespace in an OpenShift/Kubernetes cluster (such as `foo-cd` from an existing ODS project) and a project in Bitbucket (such as `FOO`).
* `git`, link:https://docs.openshift.com/container-platform/latest/cli_reference/openshift_cli/getting-started-cli.html[`oc`] (or link:https://kubernetes.io/docs/reference/kubectl/[`kubectl`]) and link:https://helm.sh[`helm`] installed locally. The plugin link:https://github.com/databus23/helm-diff[`helm-diff`] is optional but recommended.

== Installation Instructions

ODS Pipeline is packaged as a Helm chart. The installation procedure consists of three quick steps:

1. Configuring the chart values
2. Running the install script (which will deploy the Helm chart)
3. Exposing a route to the pipeline manager

=== Step 1: Configuring the chart values

Download the template and fill in the values according to the comments in that file.

[source]
----
curl -fsSL https://raw.githubusercontent.com/opendevstack/ods-pipeline/v0.14.0-preview.1/deploy/values.yaml.tmpl -o values.yaml
----

TIP: It is recommended to keep this file around after the installation so that it can be reused when updating ODS Pipeline to future versions.

=== Step 2: Running the install script

Login to the OpenShift cluster in your terminal, then run:

[source]
----
curl -fsSL https://raw.githubusercontent.com/opendevstack/ods-pipeline/v0.14.0-preview.1/deploy/install.sh | bash -s -- -n=<your_cd_namespace>
----

The script will interactively ask for credentials (such as Bitbucket access token) and will create corresponding K8s secrets. If you prefer to pass these secrets via flags, use `--help` to see all options.

IMPORTANT: If tasks need to trust a private certificate, pass `--private-cert=<host>`. This will create a K8s secret containing the certificate from the specified host, which will then be mounted in pods during task runs.

TIP: If you want to review the changes first before applying them, supply `--dry-run`.

TIP:  If you do not have access to the OpenShift API from your local machine, you can use the https://docs.openshift.com/container-platform/latest/web_console/odc-about-web-terminal.html[OpenShift Web Terminal]. Open a web terminal in the target namespace and make sure the `values.yaml` file is present in the working directory there. Then run the installation script as described above. Note that you must either install the `helm-diff` plugin using `helm plugin install https://github.com/databus23/helm-diff --version "v3.3.2"` beforehand or supply `--no-diff` when running the install script.

=== Step 3: Exposing a route to the pipeline manager

Create an HTTPS route to expose the `ods-pipeline` service. You'll need the exposed URL (together with the webhook secret that is stored in the `ods-bitbucket-webhook` K8s secret) when you create webhooks in Bitbucket repositories later.

Done, now you are ready to link:add-to-repository.adoc[enable your repositories to use ODS pipeline]!

IMPORTANT: The `pipeline` serviceaccount needs `admin` permissions in the Kubernetes namespaces it deploys to (e.g. `foo-dev` and `foo-test`). You must create rolebindings for this manually.

CAUTION: An important feature of ODS Pipeline is to retain pipeline run artifacts in Nexus and re-use them future pipeline runs (e.g. to promote built container images to another environment). For this purpose, you should create a few `raw` repositories in Nexus. These repositories should not allow re-deployment of artifacts. For example, you might want to have `ods-pipeline-dev`, `ods-pipeline-qa` and `ods-pipeline-prod` repositories, each with a different cleanup policy as fitting your needs. You can then use these repositories from your pipeline to store artifacts and enforce a progression of artifacts from DEV > QA > PROD.


== Update Instructions

The update procedure consists of two quick steps:

1. Updating the chart values if required
2. Running the install script (which will deploy the Helm chart)

=== Step 1: Updating the chart values

Ensure that the `values.yaml` file you used during installation is located in the working directory. Then check if any new values have been introduced in link:https://raw.githubusercontent.com/opendevstack/ods-pipeline/v0.14.0-preview.1/deploy/values.yaml.tmpl[`values.yaml.tmpl`] and update `values.yaml` accordingly.

TIP: If you cannot find the `values.yaml` file from the installation, create it again using the values found in the current Helm installation.

=== Step 2: Running the install script

Login to the OpenShift cluster in your terminal, then run:

[source]
----
curl -fsSL https://raw.githubusercontent.com/opendevstack/ods-pipeline/v0.14.0-preview.1/deploy/install.sh | bash -s -- -n=<your_cd_namespace>
----

TIP: If you want to review the changes first before applying them, supply `--dry-run`.

TIP: By default, the credentials stored in the K8s secrets will not be updated. If you want to make a change, pass any new values as flags to the install script (supply `--help` to see all options) or update the secrets manually.

TIP:  If you do not have access to the OpenShift API from your local machine, you can use the https://docs.openshift.com/container-platform/latest/web_console/odc-about-web-terminal.html[OpenShift Web Terminal]. Open a web terminal in the target namespace and make sure the `values.yaml` file is present in the working directory there. Then run the installation script as described above. Note that you must either install the `helm-diff` plugin using `helm plugin install https://github.com/databus23/helm-diff --version "v3.3.2"` beforehand or supply `--no-diff` when running the install script.
