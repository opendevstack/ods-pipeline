= Software Design Specification
:sectnums:
:toc:

== Purpose and Scope

The purpose of this document is to describe the technical realization of the given software system architecture and the software requirements. It states how the design meets the requirements.

== Definitions and Abbreviations

N/A

== References

N/A

== {doctitle}

=== Developed components

As described in the architecture, the system is installed into local namespaces. This document explains the individual components and their interactions.

==== ODS Pipeline Installation

===== Shared `ods-sonar` image

[cols="1,1,3"]
|===
| SDS-SHARED-1
| `ods-sonar` container image
| Container image for SQ scanning. Based on `ubi8/ubi-minimal` (SDS-EXT-2), includes software to analyze source code statically (SDS-SHARED-2, SDS-EXT-7, SDS-EXT-8 and SDS-EXT-30).

| SDS-SHARED-2
| `sonar` binary
a| Logic of SQ scanning. It runs `sonar-scanner` (SDS-EXT-7) on the sources, communicating with the SonarQube server specified by the `ods-sonar` config map and the `ods-sonar-auth` secret. After scanning, reports a generated using `cnes-report` (SDS-EXT-8) unless the scan is against a pull request. `cnes-report` is not compatible with PR scans, and reports are not needed for pull requests anyway as the evidence they provide is only needed for long-lived branches.

The project name is fixed to `<PROJECT>-<COMPONENT>`.

If the server edition supports it, the branch parameter shall be set, unless the branch being built belongs to an open PR, in which case PR analysis parameter shall be sent instead.
|===

===== Shared scripts

[cols="1,1,3"]
|===
| SDS-SHARED-3
| `supply-sonar-project-properties-default.sh` shell script
| Checks for `sonar-project.properties` file in the working directory. If that does not exist, the default properties file supplied in the container image is copied into the working directory.

| SDS-SHARED-4
| `cache-build.sh` shell script
a| Caches a build's outputs and ods artifacts to the `build-task` cache area.

Determines cache location at `$ROOT_DIR/.ods-cache/build-task/$CACHE_BUILD_KEY/$git_sha_working_dir`  where

- git_sha_working_dir is the git internal tree hash of the working directory. =$(git rev-parse "HEAD:")
- CACHE_BUILD_KEY is the value of the input parameter below

Copies artifacts to `<cache-location>/artifacts`

Copies build outputs to `<cache-location>/output`

If successful creates file `.ods-last-used-stamp` in the cache location.

Input parameters:

* `working-dir`: the sub directory in the repo whose build is cached.
* `output-dir`: sets destination directory of built binary. The files inside this directory are cached.
* `cache-build-key`: key to distinguish build toolset and build variants build from the same working directory for example for different platforms.
* `cache-location-used-path`: specifies path of the tekton task result parameter in which the location of the cache directory used is stored.

| SDS-SHARED-5
| `copy-build-if-cached.sh` shell script
a| Copies build from cache area.

If `cache-build` is not `"true"` then exit with error code 1 to signal that a build could not be retrieved from the cache (as it is not enabled).

Determines cache location at `$ROOT_DIR/.ods-cache/build-task/$CACHE_BUILD_KEY/$git_sha_working_dir`  where

- git_sha_working_dir is the git internal tree hash of the working directory. =$(git rev-parse "HEAD:")
- CACHE_BUILD_KEY is the value of the input parameter below.

If there is no directory at `<cache-location>` exit with error code 1 to signal that a build could not be retrieved from the cache.

Copy artifacts inside `<cache-location>/artifacts` to `${ROOT_DIR}/.ods/artifacts`

Copy output files inside `<cache-location>/output` to `$OUTPUT_DIR`

Write the cache-location to file `$CACHE_LOCATION_USED_PATH`.

Touch file `.ods-last-used-stamp` in the cache location so that the cleanup timestamp is reset.

Input parameters:

* `working-dir`: the sub directory in the repo whose build is cached.
* `output-dir`: sets destination directory of built binary. The files inside this directory are cached.
* `cache-build`: controls whether build cache is used.
* `cache-build-key`: key to distinguish build toolset and build variants build from the same working directory for example for different platforms.
* `cache-location-used-path`: specifies path of the tekton task result parameter in which the location of the cache directory used is stored.

|===


===== `ods-build-go` task

[cols="1,1,3"]
|===
| SDS-TASK-1
| `ods-build-go` Task resource
a| The task defines two steps:

. Build Go (module) applications (referencing SDS-TASK-2 and executing SDS-TASK-3).
  This step supports build skipping (executing SDS-SHARED-5 and/or SDS-SHARED-4 if enabled with parameter `cache-build`)
. Analyze source code (referencing SDS-SHARED-1 and executing SDS-SHARED-2)

Input parameters:

* `working-dir`: allows customizing which directory is used as the Go module root. If set, artifacts are prefixed with `<SUBDIRECTORY>-`, and the SQ project is suffixed with `-<SUBDIRECTORY>`.
* `enable-cgo`: allows to enable `CGO`
* `go-os`: sets target operating system (`GOOS`)
* `go-arch`: sets target architecture (`GOARCH`)
* `output-dir`: sets destination directory of built binary
* `pre-test-script`: specifies script to run prior to tests
* `build-script`: specifies path to build script
* `sonar-quality-gate`: enables quality gate check
* `sonar-skip`: skips SonarQube analysis
* `cache-build`: if 'true' build skipping is enabled.

| SDS-TASK-2
| `ods-go-toolset` container image
| Container image for building Go applications. Based on `ubi8/go-toolset` (SDS-EXT-25), includes SDS-EXT-4,EXT- SDS-EXT-5, SDS-SHARED-3, SDS-TASK-3 and SDS-TASK-25.

| SDS-TASK-3
| `build-go.sh` shell script
a| The go module cache is configured to be on the cache location of the PVC by setting environment variable `GOMODCACHE` to `.ods-cache/deps/gomod` (see https://go.dev/ref/mod#module-cache)

Runs `gofmt` (SDS-EXT-3) to check all Go files are formatted.

Runs `golangci-lint` (SDS-EXT-4) to check if there are any lint errors. A report is placed into `.ods/artifacts/lint-reports`.

If the `pre-test-script` is set, it executes the given script before running tests.

Runs `go test`, excluding the `vendor` directory, creating code coverage and xUnit report (using SDS-EXT-5). The artifacts are placed in the working directory and in `.ods/artifacts/code-coverage` and `.ods/artifacts/xunit-reports`, respectively. If the artifacts are already found in `.ods/artifacts`, then testing is skipped and the artifacts are copied to the working directory to expose them to SonarQube.

Builds Go application (using SDS-EXT-3, optionally SDS-EXT-6) into specified output directory.

Supplies default SonarQube project properties file if required (SDS-SHARED-3).

| SDS-TASK-25
| `go.properties` properties file
| Default configuration for Go SonarQube project.
|===

===== `ods-build-gradle` task

[cols="1,1,3"]
|===
| SDS-TASK-4
| `ods-build-gradle` Task resource
a| The task defines two steps:

. Build Gradle module  (referencing SDS-TASK-5 and executing SDS-TASK-6)
. Analyze source code (referencing SDS-SHARED-1 and executing SDS-SHARED-2)

Input parameters:

* `working-dir`: allows customizing which directory is used as the Gradle module root. If set, artifacts are prefixed with `<SUBDIRECTORY>-`, and the SQ project is suffixed with `-<SUBDIRECTORY>`.
* `gradle-additional-tasks`: additional gradle tasks to be passed to the gradle build
* `gradle-options`: options to be passed to the gradle build
* `output-dir`: sets destination directory of built binary
* `build-script`: specifies path to build script
* `sonar-quality-gate`: enables quality gate check
* `sonar-skip`: skips SonarQube analysis

| SDS-TASK-5
| `ods-gradle-toolset` container image
| Container image for building Gradle modules. Based on `ubi8/openjdk-17` (SDS-EXT-11), includes SDS-EXT-12, SDS-EXT-30, SDS-SHARED-3, SDS-TASK-6 and SDS-TASK-26.

| SDS-TASK-6
| `build-gradle.sh` shell script
a| Builds a Gradle module that provides a gradle build script into `docker/app.jar`.

The destination directory can be changed by exporting the environment variable `ODS_OUTPUT_DIR`.

Runs `gradlew clean build` to build the Gradle module, using options and additional tasks as passed from SDS-TASK-4.

Generated unit test reports are placed in the working directory (for SonarQube to pick them up) and copied into `.ods/artifacts/xunit-reports`.

Generated unit test coverage report are placed in the working directory (for SonarQube to pick them up) and copied into `.ods/artifacts/code-coverage`.

Supplies default SonarQube project properties file if required (SDS-SHARED-3).

| SDS-TASK-26
| `gradle.properties` properties file
| Default configuration for Gradle SonarQube project.
|===

===== `ods-start` task

[cols="1,1,3"]
|===
| SDS-TASK-7
| `ods-start` Task resource
a| Task to start pipeline. References SDS-TASK-8 and executes SDS-TASK-9.

Input parameters: TODO

| SDS-TASK-8
| `ods-start` container image
| Container image to start a pipeline. Based on `ubi8/ubi-minimal` (SDS-EXT-2), includes SDS-EXT-9, SDS-EXT-13, SDS-EXT-22, SDS-EXT-27, SDS-EXT-30 and SDS-TASK-9.

| SDS-TASK-9
| `start` binary
a| The task checks out the repository of a given URL and Git ref into the mounted workspace, cleaning previous contents, except for the caching area at `./ods-cache`. If the checked out `ods.y(a)ml` configures any child repositories, those are checked out as well from the configured URL and Git ref. If a release branch (`release/<VERSION>`) corresponding to the current version exists, it is preferred. All checkouts are shallow and include submodules.

A build task may store cached dependencies under directory `.ods-cache/deps/<technology-name>/` where technology-name provides a namespace. For example this could be 'npm' if at some point in the future this would be supported. The task deletes files in folder `.ods-cache/deps/`. All other files in `.ods-cache` are reserved for future use. While they are not removed you must not rely on those locations except for experimentation.

Context information is stored under `.ods` for each checked out repository:

* repository related information: project key, component key, repository name, Git URL, Git (full) ref, Git commit SHA, pull request base and pull request key.
* OpenShift related information: namespace
* deployment related information: version and environment

Any artifacts in Nexus belonging to the same commit being built are downloaded and placed into the respective `.ods/artifacts` folder of each checked out repository.

The Bitbucket build status of the commit being built is set to "in progress". The build status links back to the pipeline run.

If any child repository is missing a successful pipeline run artifact for the checked out commit, the task fails.
|===

===== `ods-finish` task

[cols="1,1,3"]
|===
| SDS-TASK-10
| `ods-finish` Task resource
a| Task to finish pipeline. References SDS-TASK-11 and executes SDS-TASK-12.

Input parameters: TODO

| SDS-TASK-11
| `ods-finish` container image
| Container image to start a pipeline. Based on `ubi8/ubi-minimal` (SDS-EXT-2), includes SDS-EXT-30 and SDS-TASK-12.

| SDS-TASK-12
| `finish` binary
a| Sets the Bitbucket build status to "failed" or "successful", depending on whether all tasks succeeded or not. The build status links back to the pipeline run.

Creates an artifact for the pipeline run, containing its name and status, provided that all tasks succeeded.

Uploads all files in any `.ods/artifacts` folder to Nexus, storing them in a group named `/<PROJECT>/<REPOSITORY>/<GIT-COMMIT-SHA>`, provided that all tasks succeeded.

| SDS-TASK-29
| `finish` binary
a| Optionally sends a status notification to a webhook receiver.

Status notification message, webhook URL, content type, HTTP method, and triggering status values may be configured via a `ConfigMap`.

|===

===== `ods-build-python` task

[cols="1,1,3"]
|===
| SDS-TASK-13
| `ods-build-python` Task resource
a| The task defines two steps:

. Build Python applications (referencing SDS-TASK-14 and executing SDS-TASK-15).
  This step supports build skipping (executing SDS-SHARED-5 and/or SDS-SHARED-4 if enabled with parameter `cache-build`)
. Analyze source code (referencing SDS-SHARED-1 and executing SDS-SHARED-2)

Input parameters:

* `build-script`: specifies path to build script

| SDS-TASK-14
| `ods-python-toolset` container image
| Container image to build Python applications. Based on `ubi8/python-39` (SDS-EXT-28), includes SDS-SHARED-3, SDS-TASK-15 and SDS-TASK-27.

| SDS-TASK-15
| `build-python.sh` shell script
a| Runs `mypy` and `flake8` to lint source code and fails if there are any findings. The maximum allowed line length defaults to 120 can be set by the `max-line-length` task parameter.

If the `pre-test-script` is set, it executes the given script before running tests.

Runs `pytest`, creating code coverage and xUnit reports. The artifacts are placed in the working directory and in `.ods/artifacts/code-coverage` and `.ods/artifacts/xunit-reports`, respectively.

Builds Python application into the directory specified by `output-dir`.

Supplies default SonarQube project properties file if required (SDS-SHARED-3).

| SDS-TASK-27
| `python.properties` properties file
| Default configuration for Python SonarQube project.
|===

===== `ods-build-npm` task

[cols="1,1,3"]
|===
| SDS-TASK-16
| `ods-build-npm` Task resource
a| The task defines two steps:

. Build Node.js applications using npm (referencing SDS-TASK-17 and executing SDS-TASK-18).
  This step supports build skipping (executing SDS-SHARED-5 and/or SDS-SHARED-4 if enabled with parameter `cache-build`)
. Analyze source code (referencing SDS-SHARED-1 and executing SDS-SHARED-2)

Input parameters:

* `working-dir`: allows customizing which directory is used as the Node.js module root. If set, artifacts are prefixed with `<SUBDIRECTORY>-`, and the SQ project is suffixed with `-<SUBDIRECTORY>`.
* `output-dir`: sets destination directory of the build output
* `build-dir`: sets source directory of the build output
* `copy-node-modules`: enables copying node_modules directory to the output directory
* `max-lint-warnings`: maximum of allowed linting warnings after which eslint will exit with an error
* `lint-file-ext`: file extensions to lint
* `build-script`: specifies path to build script
* `sonar-quality-gate`: enables quality gate check
* `sonar-skip`: skips SonarQube analysis
* `cache-build`: if 'true' build skipping is enabled.

| SDS-TASK-17
| `ods-node16-npm-toolset` container image
| Container image to build Node.js applications using npm. Based on `ubi8/nodejs-16` (SDS-EXT-26), includes SDS-SHARED-3, SDS-TASK-18 and SDS-TASK-28.

| SDS-TASK-18
| `build-npm.sh` shell script
a| Checks that package.json and package-lock.json exist to require best practice of using lock files. See also https://github.com/opendevstack/ods-pipeline/discussions/411

Runs `npm run build`, and copies the files inside the directory specified in `build-dir` into directory `dist` which is placed into the directory specified by `output-dir`.

If `copy-node-modules` is `true` the `node_modules` directory is copied into the mentioned dist directory.

For traceability package.json and package-lock.json are copied into the `dist` directory inside the output directory as well. This happens at the end of the script execution to avoid confusing the subsequent running of tests.

Runs `npm run test`, creating code coverage and xUnit reports. The artifacts are placed in the working directory and in `.ods/artifacts/code-coverage` and `.ods/artifacts/xunit-reports`, respectively.

Runs `npm run lint` to lint the source code. If there are any errors or warnings, the script should exit with a non-zero exit code.

Supplies default SonarQube project properties file if required (SDS-SHARED-3).

| SDS-TASK-28
| `npm.properties` properties file
| Default configuration for npm SonarQube project.
|===

==== `ods-package-image` task

[cols="1,1,3"]
|===
| SDS-TASK-19
| `ods-package-image` Task resource
| Builds and scans a container image, then pushes it to a registry. References SDS-TASK-20 and executes SDS-TASK-21.

| SDS-TASK-20
| `ods-package-image` container image
| Container image to build, scan and push images. Based on `ubi8` (SDS-EXT-1), includes SDS-EXT-17, SDS-EXT-18, SDS-EXT-31 and SDS-TASK-21. If the build argument `aquasecScannerUrl` is set, the referenced Aqua Scanner binary is installed into the image as well.

| SDS-TASK-21
| `build-and-push` binary
a| Checks if an image with the tag to built exist already in the target registry, and if so, skips the build.

Builds a container image using SDS-EXT-18:

* The Docker context directory defaults to `docker` and can be overwritten by the `docker-dir` parameter.
* The Dockerfile defaults to `Dockerfile`, and can be overwritten by `dockerfile` parameter. The location is relative to the Docker context directory.
* The resulting image name and SHA is placed into `.ods/artifacts`.

Pushes the image to the target registry (defaulting to an image stream in the namespace of the pipeline run) using SDS-EXT-17.

Generates the SBOM report of the image using SDS-EXT-31. The resulting report is placed in `.ods/artifacts/sboms/<image-name>.spdx` in link:https://spdx.dev/[SPDX] format.

If the Aqua scanner is installed in the base image, the  pushed image shall be scanned. The resulting report is placed in `.ods/artifacts` and attached as a code insight to Bitbucket.
|===

==== `ods-deploy-helm` task

[cols="1,1,3"]
|===
| SDS-TASK-22
| `ods-deploy-helm` Task resource
| Deploys a Helm chart and promotes images. References SDS-TASK-23 and executes SDS-TASK-24.

| SDS-TASK-23
| `ods-helm` container image
| Container image to promote images and deploy Helm charts. Based on `ubi8/ubi-minimal` (SDS-EXT-2), includes SDS-EXT-9, SDS-EXT-15, SDS-EXT-17, SDS-EXT-19, SDS-EXT-20, SDS-EXT-21, SDS-EXT-23, SDS-EXT-24, SDS-EXT-30 and SDS-TASK-24.

| SDS-TASK-24
| `deploy-helm` binary
a| Skips when no `environment` is given.

Pushes images into the target namespace.

* The images that are pushed are determined by the artifacts in `.ods/artifacts/image-digests`. Each artifact contains information from which registry / image stream to get the images.
* The target namespace is selected from the given `environment`.
* The target registry may also be external to the cluster in which the pipeline runs. The registry is identified by the `registryHost` field of the environment configuration, and the credential token of `apiCredentialsSecret` is used to authenticate.

Upgrades (or installs) a Helm chart.

* The Helm chart is expected at the location identified by the `chartDir` parameter (defaulting to `chart`).
* The task errors if no chart can be found.
* A diff is performed before the upgrade/install. If there are no differences, upgrade/install is skipped.
* The upgrade/install waits until all Pods, PVCs, Services, and minimum number of Pods of a Deployment, StatefulSet, or ReplicaSet are in a ready state before marking the release as successful.
* Any values and secrets files corresponding to the environment and stage are respected (`values.yaml`, `secrets.yaml`, `values.<STAGE>.yaml`, `secrets.<STAGE>.yaml`, `values.<ENVIRONMENT>.yaml`, `secrets.<ENVIRONMENT>.yaml`; in that order of specificity).
* A values file containing the Git commit SHA is auto-generated and added to the Helm diff/upgrade invocation.
* Any encrypted secrets files are decrypted on the fly, using the age key provided by the `Secret` identified by the `age-key-secret` parameter (defaulting to `helm-secrets-age-key`). The secret is expected to expose the age key under the `key.txt` field.
* The "app version" is set to the Git commit SHA and the "version" is set to given `version` if any, otherwise the chart version in `Chart.yaml`.
* Charts in any of the repositories configured in `ods.y(a)ml` are packaged according to the same rules and added as subcharts.
* The target namespace may also be external to the cluster in which the pipeline runs. The API server is identified by the `apiServer` field of the environment configuration, and the credential token of `apiCredentialsSecret` is used to authenticate.
|===

===== Pipeline Manager

[cols="1,1,3"]
|===
| SDS-PIPELINE-MANAGER-1
| `ods-pipeline` Service resource
| Service (exposing a set of pods) for the pipeline manager

| SDS-PIPELINE-MANAGER-2
| `ods-pipeline` Deployment resource
| Deployment (providing declarative updates for pods and replica sets) for the pipeline manager. The container template references SDS-PIPELINE-MANAGER-3.

| SDS-PIPELINE-MANAGER-3
| `ods-pipeline-manager` container image
| Container image to intercept Tekton Trigger events coming from Bitbucket webhooks. Based on `ubi8/ubi-minimal` (SDS-EXT-2), includes SDS-EXT-30 and SDS-PIPELINE-MANAGER-4.

| SDS-PIPELINE-MANAGER-4
| `pipeline-manager` binary
a| The pipeline manager parses the JSON payload and triggers a pipeline run dependent on the events received.

For Git commits of which the commit message instructs skipping CI, no pipelines are triggered. Instructions may be anywhere in the commit message and may be one of (case-insensitive):

[source]
----
[ci skip]
[skip ci]
***NO_CI***
----

A pipeline run is created based on the ODS config file read from the Git ref of the repository corresponding to the webhook request.

A PVC is created per repository unless it exists already. The name is equal to `ods-workspace-<component>` (shortened to 63 characters if longer). This PVC is then used in the pipeline run as a shared workspace.

When no other pipeline run for the same repository is running or pending, the created pipeline run starts immediately. Otherwise a pending pipeline run is created, and a periodic polling is kicked off to allow the run to start once possible. Since the pipeline manager does not persist state about pending pipeline runs, polling is also started for all repositories in the related Bitbucket project when the server boots.

Pipelines runs are pruned when a webhook trigger is received. Pipeline runs that are newer than the configured time window are protected from pruning. Older pipeline runs are cleaned up to not grow beyond the configured maximum amount. The pruning strategy is applied per repository and stage (DEV, QA, PROD) to avoid aggressive pruning of QA and PROD pipeline runs.
|===

===== Artifact Download

[cols="1,1,3"]
|===
| SDS-DLD-1
| `artifact-download` binary
a| The binary receives flags from the user identifying:

* OpenShift namespace
* Git repository (project/repository)
* Git tag

The OpenShift namespace is used to retrieve configuration and secrets required to communicate with Bitbucket and Nexus. The `ods.yaml` of the Git repository is retrieved at given Git tag to detect any subrepositories. If the given tag is `WIP`, the repository information is not retrieved from Bitbucket but located from the `.git` directory in the working directory.

For all repositories in scope, the artifacts in the corresponding groups in Nexus are downloaded to the local host. The files are placed into `artifacts-out/<TAG>` (customizable via `--output`).
|===

===== Installation / Update

[cols="1,1,3"]
|===
| SDS-SETUP-1
| Helm chart `ods-pipeline`
a| The Helm chart consists of three subhcharts:

* `images`: Contains `BuildConfig`/`ImageStream` resources
* `tasks`: Contains `Task` resources
* `setup`: Contains resources related to the pipeline manager and config maps / secrets supporting pipeline runs

The `images` chart is only used within an OpenShift context. It contains a `post-install/upgrade` hook which starts builds for all available `BuildConfig` resources to automatically build new container images to be used in tasks and the pipeline manager.

| SDS-SETUP-2
| `web-terminal-install.sh` script
a| The script is supposed to be downloaded and piped into bash. The script installs the prerequisites not already present in the Web Terminal image (Helm plugin `helm-diff`), clones the Git repository and then runs `./install.sh`.

| SDS-SETUP-3
| `install.sh` script
a| The script installs the Helm chart located in `deploy/ods-pipeline`. Further, it:

* creates the `pipeline` serviceaccount if it does not exist already
* creates secrets holding relevant credentials (e.g. Bitbucket access token), either by prompting the user for values, or taking input from command line flags
* in case of an update, modifies existing secrets when command line flags are given
* adds the `tekton.dev/git-0` annotation to the `ods-bitbucket-auth` secret (pointing to the Bitbucket URL) and associate the secret with the `pipeline` serviceaccount to enable `git clone`` in the `ods-start` task
|===


=== Third-party components

[cols="1,1,1,2,1"]
|===
|ID |Name |Version |Description |Link

| SDS-EXT-1
| Red Hat Universal Base Image 8
| 8.4
| Universal Base Image is designed and engineered to be the base layer for a wide range of applications, middleware and utilities. It is maintained by Red Hat and updated regularly.
| https://catalog.redhat.com/software/containers/ubi8/ubi/5c359854d70cc534b3a3784e

| SDS-EXT-2
| Red Hat Universal Base Image 8 Minimal
| 8.4
| Universal Base Image Minimal is a stripped down image that uses microdnf as a package manager. It is maintained by Red Hat and updated regularly.
| https://catalog.redhat.com/software/containers/ubi8/ubi-minimal/5c359a62bed8bd75a2c3fba8

| SDS-EXT-3
| Go
| 1.16
| Go toolchain.
| https://golang.org

| SDS-EXT-4
| golangci-lint
| 1.45
| golangci-lint is a Go linters aggregator.
| https://golangci-lint.run

| SDS-EXT-5
| junit-report
| 2.0
| Converts go test output to an xml report, suitable for applications that expect junit xml reports.
| https://github.com/jstemmer/go-junit-report

| SDS-EXT-6
| gcc/gcc-c++
| 8.5
| Optimizing compiler supporting various programming languages, required for CGO.
| https://gcc.gnu.org

| SDS-EXT-7
| sonar-scanner
| 3.1
| General purpose SonarQube scanner
| https://github.com/SonarSource/sonar-scanner-cli

| SDS-EXT-8
| cnes-report
| 3.2
| Exports code analysis from a SonarQube server in various file formats.
| https://github.com/cnescatlab/sonar-cnes-report

| SDS-EXT-9
| Git
| 2.31
| Distributed version control system.
| https://git-scm.com

| SDS-EXT-11
| Red Hat OpenJDK 17 Image
| 1.13
| OpenJDK 17 container is a base platform for building and running plain Java 17 applications, e.g. fat-jar and flat classpath.
| https://catalog.redhat.com/software/containers/ubi8/openjdk-17/618bdbf34ae3739687568813

| SDS-EXT-12
| Gradle
| 7.4.2
| Build automation tool for multi-language software development.
| https://gradle.org

| SDS-EXT-13
| openssh-clients
| 8.0
| Clients necessary to make encrypted connections to SSH servers.
| https://www.openssh.com

| SDS-EXT-15
| Tar
| 1.30
| Used to create and extract archive files.
| https://www.gnu.org/software/tar/

| SDS-EXT-17
| Skopeo
| 1.9
| Tool for moving container images between different types of container storages.
| https://github.com/containers/skopeo

| SDS-EXT-18
| Buildah
| 1.27
| Tool that facilitates building OCI images.
| https://github.com/containers/buildah

| SDS-EXT-19
| Helm
| 3.5
| Package manager for Kubernetes.
| https://helm.sh

| SDS-EXT-20
| Helm Diff plugin
| 3.3
| Shows a diff explaining what a helm upgrade would change.
| https://github.com/databus23/helm-diff

| SDS-EXT-21
| Helm Secrets plugin
| 3.10
| Manages secrets with Git workflow.
| https://github.com/jkroepke/helm-secrets

| SDS-EXT-22
| Tekton
| 0.24
| Cloud-native Pipeline resource.
| https://github.com/tektoncd/pipeline

| SDS-EXT-23
| Sops
| 3.7
| Encrypted files management tool.
| https://github.com/mozilla/sops

| SDS-EXT-24
| Age
| 1.0
| File encryption tool, format and Go library with small explicit keys.
| https://github.com/FiloSottile/age

| SDS-EXT-25
| Go Toolset for UBI 8
| 1.18
| go-toolset available as a container is a base platform for building and running various Go applications and frameworks. It is maintained by Red Hat and updated regularly.
| https://catalog.redhat.com/software/containers/ubi8/go-toolset/5ce8713aac3db925c03774d1

| SDS-EXT-26
| NodeJS 16 for UBI 8
| 1
| Node.js 16 available as container is a base platform for building and running various Node.js 16 applications and frameworks. It is maintained by Red Hat and updated regularly.
| https://catalog.redhat.com/software/containers/ubi8/nodejs-16/615aee9fc739c0a4123a87e1

| SDS-EXT-27
| Git LFS
| 3.0.2
| Git Large File Storage extension for versioning large files.
| https://git-lfs.github.com/

| SDS-EXT-28
| Python 3.9 for UBI 8
| 1
| Python 3.9 available as container is a base platform for building and running various Python applications and frameworks. It is maintained by Red Hat and updated regularly.
| https://catalog.redhat.com/software/containers/ubi8/python-39/6065b24eb92fbda3a4c65d8f

| SDS-EXT-29
| GNU findutils
| 4.6
| Basic directory searching utilities, included due to the dependency of `helm-secrets` on `xargs`
| https://www.gnu.org/software/findutils/

| SDS-EXT-30
| OpenSSL
| 1.1
| Toolkit for general-purpose cryptography and secure communication.
| https://www.openssl.org

| SDS-EXT-31
| Trivy
| 0.36.0
| Security scanner CLI.
| https://www.trivy.dev/

|===

== Appendix

N/A

== Document History

As this document is version controlled in Git, all changes are tracked as commits. The history of changes to this file can be retrieved via `git log --oneline --no-merges docs/design/software-design-specification.adoc`.
